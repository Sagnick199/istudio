#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Face Recognition using PCA (Eigenfaces) + ANN (from-scratch backprop)
- Builds face database
- Performs PCA with surrogate covariance
- Trains a simple feedforward ANN on eigenface signatures
- Evaluates across multiple k (number of eigenfaces) and plots Accuracy vs k
- Performs "imposter" (open-set) detection using a softmax-confidence threshold
Author: Generated by ChatGPT (GPT-5 Thinking)
"""
import os
import io
import sys
import math
import time
import json
import random
import zipfile
import hashlib
import argparse
from dataclasses import dataclass
from typing import List, Tuple, Dict

import numpy as np
import cv2
import matplotlib.pyplot as plt

# ------------------------------
# Utilities
# ------------------------------

def set_seed(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)

def ensure_dir(path: str):
    os.makedirs(path, exist_ok=True)

def download_dataset_if_needed(dataset_root: str, url: str = "https://raw.githubusercontent.com/robaita/introduction_to_machine_learning/main/dataset.zip"):
    """
    Downloads the dataset.zip from the given GitHub raw URL if not present locally,
    then extracts into dataset_root.
    """
    ensure_dir(dataset_root)
    zip_path = os.path.join(dataset_root, "dataset.zip")
    if not os.path.exists(zip_path) and not any(os.scandir(dataset_root)):
        try:
            import urllib.request
            print(f"[INFO] Downloading dataset.zip to {zip_path} ...")
            urllib.request.urlretrieve(url, zip_path)
            print("[INFO] Download complete.")
        except Exception as e:
            print("[WARN] Could not download dataset automatically:", e)
            print("[HINT] Please manually download dataset.zip from:")
            print("       https://github.com/robaita/introduction_to_machine_learning/blob/main/dataset.zip")
            print("       Then place it inside:", dataset_root)
    # Extract if zip exists and folder not extracted yet
    if os.path.exists(zip_path):
        with zipfile.ZipFile(zip_path, 'r') as z:
            # Check if extraction seems needed (no images in root)
            has_images = False
            for root, dirs, files in os.walk(dataset_root):
                if any(f.lower().endswith(('.png','.jpg','.jpeg','.bmp')) for f in files):
                    has_images = True
                    break
            if not has_images:
                print("[INFO] Extracting dataset.zip ...")
                z.extractall(dataset_root)
                print("[INFO] Extraction complete.")

# ------------------------------
# Data Loading
# ------------------------------

@dataclass
class Dataset:
    X: np.ndarray           # (mn, p) column-stacked face vectors (float32)
    y: np.ndarray           # (p,) integer labels 0..(C-1)
    subjects: List[str]     # mapping index -> subject/class name
    shape_hw: Tuple[int,int]

def load_images_from_folder(folder: str, img_size: Tuple[int,int]=(64,64)) -> Dataset:
    """
    Expected folder organization:
      folder/
        person1/ img1.jpg, img2.jpg, ...
        person2/ ...
    Any images found at any depth will be read; subfolder name is label.
    """
    if not os.path.isdir(folder):
        raise FileNotFoundError(f"Dataset folder not found: {folder}")
    subjects = []
    data = []
    labels = []

    # Collect class folders
    class_dirs = []
    for entry in sorted(os.scandir(folder), key=lambda e: e.name):
        if entry.is_dir():
            class_dirs.append(entry.path)

    # If no subfolders, assume flat folder (all images belong to a single subject "subject0")
    if not class_dirs:
        class_dirs = [folder]
        subjects = ["subject0"]
    else:
        subjects = [os.path.basename(d) for d in class_dirs]

    label_map = {name:i for i,name in enumerate(subjects)}

    img_h, img_w = img_size
    for class_dir in class_dirs:
        class_name = os.path.basename(class_dir) if class_dirs != [folder] else "subject0"
        label = label_map[class_name]
        for root, _, files in os.walk(class_dir):
            for f in sorted(files):
                if f.lower().endswith(('.png','.jpg','.jpeg','.bmp','.pgm')):
                    fp = os.path.join(root, f)
                    img = cv2.imread(fp, cv2.IMREAD_GRAYSCALE)
                    if img is None:
                        continue
                    img = cv2.resize(img, (img_w, img_h), interpolation=cv2.INTER_AREA)
                    vec = img.astype(np.float32).reshape(-1,1)  # column vector
                    data.append(vec)
                    labels.append(label)

    if len(data) == 0:
        raise RuntimeError("No images found. Check dataset folder structure and file extensions.")

    X = np.concatenate(data, axis=1)   # (mn, p)
    y = np.array(labels, dtype=np.int32)
    return Dataset(X=X, y=y, subjects=subjects, shape_hw=(img_h, img_w))

# ------------------------------
# PCA (Eigenfaces) via surrogate covariance
# ------------------------------

@dataclass
class PCAResult:
    mean: np.ndarray        # (mn, 1)
    eigenfaces: np.ndarray  # (mn, k) columns are eigenfaces
    eigenvalues: np.ndarray # (k,)
    proj_mat: np.ndarray    # alias for eigenfaces (mn, k)
    k: int
    shape_hw: Tuple[int,int]

def pca_eigenfaces(X: np.ndarray, k: int) -> PCAResult:
    """
    X: (mn, p) matrix of column vectors
    k: number of principal components/eigenfaces to keep
    Returns mean, eigenfaces (mn,k), eigenvalues (k,).
    """
    mn, p = X.shape
    # 1) Mean
    M = np.mean(X, axis=1, keepdims=True)   # (mn,1)
    # 2) Center
    D = X - M                                # (mn,p)
    # 3) Surrogate covariance: S = D^T D (p x p)
    # Compute eigenvectors of S, map back to original space
    S = D.T @ D                              # (p,p)
    # Numerical stability: use float64 during eig
    S = S.astype(np.float64)
    # 4) Eigendecomposition of S
    eigvals, eigvecs = np.linalg.eigh(S)     # eigh since S is symmetric
    # Sort descending
    idx = np.argsort(eigvals)[::-1]
    eigvals = eigvals[idx]
    eigvecs = eigvecs[:, idx]                # (p,p)
    # 5) Select top k
    k = max(1, min(k, p))
    eigvals_k = eigvals[:k]
    eigvecs_k = eigvecs[:, :k]               # (p,k)
    # 6) Map to original space: U = D * V * (1/sqrt(lambda))
    # Handle small eigvals
    eps = 1e-10
    inv_sqrt = 1.0 / np.sqrt(np.maximum(eigvals_k, eps))
    U = (D @ eigvecs_k) * inv_sqrt          # (mn,k)
    # Normalize eigenfaces
    U_norm = U / (np.linalg.norm(U, axis=0, keepdims=True) + 1e-12)
    return PCAResult(mean=M.astype(np.float32),
                     eigenfaces=U_norm.astype(np.float32),
                     eigenvalues=eigvals_k.astype(np.float32),
                     proj_mat=U_norm.astype(np.float32),
                     k=k,
                     shape_hw=None)

def project(X: np.ndarray, M: np.ndarray, eigenfaces: np.ndarray) -> np.ndarray:
    """
    Project mean-centered data onto eigenfaces.
    X: (mn,p)
    M: (mn,1)
    eigenfaces: (mn,k)
    Returns: Omega (k,p)
    """
    D = X - M
    Omega = eigenfaces.T @ D
    return Omega

# ------------------------------
# Simple ANN (from-scratch) for classification
# ------------------------------

@dataclass
class ANNConfig:
    input_dim: int
    hidden_dims: Tuple[int, ...] = (128, 64)
    num_classes: int = 2
    lr: float = 0.01
    weight_decay: float = 0.0005
    epochs: int = 50
    batch_size: int = 32
    seed: int = 42

class SimpleANN:
    def __init__(self, cfg: ANNConfig):
        set_seed(cfg.seed)
        self.cfg = cfg
        # Xavier init
        dims = [cfg.input_dim] + list(cfg.hidden_dims) + [cfg.num_classes]
        self.W = []
        self.b = []
        for i in range(len(dims)-1):
            in_d, out_d = dims[i], dims[i+1]
            limit = math.sqrt(6.0/(in_d+out_d))
            self.W.append(np.random.uniform(-limit, limit, (in_d, out_d)).astype(np.float32))
            self.b.append(np.zeros((1, out_d), dtype=np.float32))

    @staticmethod
    def relu(x): return np.maximum(0, x)
    @staticmethod
    def relu_grad(x): return (x > 0).astype(np.float32)

    @staticmethod
    def softmax(logits):
        logits = logits - np.max(logits, axis=1, keepdims=True)
        exp = np.exp(logits)
        return exp / (np.sum(exp, axis=1, keepdims=True) + 1e-12)

    @staticmethod
    def one_hot(y, C):
        oh = np.zeros((y.shape[0], C), dtype=np.float32)
        oh[np.arange(y.shape[0]), y] = 1.0
        return oh

    def forward(self, X):
        """
        Returns caches for backprop
        """
        caches = []
        A = X
        for i in range(len(self.W)-1):
            Z = A @ self.W[i] + self.b[i]
            A = self.relu(Z)
            caches.append((Z, A))
        # Last layer (linear -> softmax)
        ZL = A @ self.W[-1] + self.b[-1]
        P = self.softmax(ZL)
        caches.append((ZL, P))
        return P, caches

    def compute_loss(self, P, y):
        C = self.cfg.num_classes
        Y = self.one_hot(y, C)
        # cross entropy
        eps = 1e-12
        loss = -np.sum(Y * np.log(P + eps)) / y.shape[0]
        # L2 regularization
        l2 = sum(np.sum(W*W) for W in self.W)
        loss += self.cfg.weight_decay * 0.5 * l2
        return loss

    def backward(self, X, y, caches):
        grads_W = [np.zeros_like(W) for W in self.W]
        grads_b = [np.zeros_like(b) for b in self.b]
        C = self.cfg.num_classes
        Y = self.one_hot(y, C)

        # Forward recompute (to get the hidden activations)
        As = [X]  # input as A0
        Zs = []
        A = X
        for i in range(len(self.W)-1):
            Z = A @ self.W[i] + self.b[i]
            A = self.relu(Z)
            Zs.append(Z)
            As.append(A)
        ZL = As[-1] @ self.W[-1] + self.b[-1]
        P = self.softmax(ZL)

        # dL/dZL
        dZL = (P - Y) / X.shape[0]  # (N,C)
        grads_W[-1] = As[-1].T @ dZL + self.cfg.weight_decay * self.W[-1]
        grads_b[-1] = np.sum(dZL, axis=0, keepdims=True)

        # Backprop through hidden layers
        dA = dZL @ self.W[-1].T
        for i in reversed(range(len(self.W)-1)):
            dZ = dA * self.relu_grad(Zs[i])
            grads_W[i] = As[i].T @ dZ + self.cfg.weight_decay * self.W[i]
            grads_b[i] = np.sum(dZ, axis=0, keepdims=True)
            if i > 0:
                dA = dZ @ self.W[i].T
        return grads_W, grads_b

    def fit(self, X, y, X_val=None, y_val=None, verbose=True):
        N = X.shape[0]
        for epoch in range(1, self.cfg.epochs + 1):
            # Shuffle
            idx = np.random.permutation(N)
            Xs = X[idx]
            ys = y[idx]

            # Mini-batch SGD
            for start in range(0, N, self.cfg.batch_size):
                end = start + self.cfg.batch_size
                xb = Xs[start:end]
                yb = ys[start:end]
                P, caches = self.forward(xb)
                grads_W, grads_b = self.backward(xb, yb, caches)
                # Update
                for i in range(len(self.W)):
                    self.W[i] -= self.cfg.lr * grads_W[i]
                    self.b[i] -= self.cfg.lr * grads_b[i]

            # Epoch metrics
            P_train, _ = self.forward(X)
            train_loss = self.compute_loss(P_train, y)
            train_acc = self.accuracy(X, y)
            if verbose:
                if X_val is not None and y_val is not None:
                    val_acc = self.accuracy(X_val, y_val)
                    print(f"[Epoch {epoch:03d}] loss={train_loss:.4f} train_acc={train_acc:.3f} val_acc={val_acc:.3f}")
                else:
                    print(f"[Epoch {epoch:03d}] loss={train_loss:.4f} train_acc={train_acc:.3f}")

    def predict_proba(self, X):
        P, _ = self.forward(X)
        return P

    def predict(self, X):
        P = self.predict_proba(X)
        return np.argmax(P, axis=1)

    def accuracy(self, X, y):
        yhat = self.predict(X)
        return (yhat == y).mean()

# ------------------------------
# Splits and helpers
# ------------------------------

def per_subject_split(X: np.ndarray, y: np.ndarray, train_ratio=0.6, seed=42):
    """
    Returns train/test indices ensuring ~train_ratio per subject.
    """
    set_seed(seed)
    train_idx, test_idx = [], []
    classes = np.unique(y)
    for c in classes:
        idx = np.where(y == c)[0].tolist()
        random.shuffle(idx)
        n_train = max(1, int(len(idx) * train_ratio))
        train_idx += idx[:n_train]
        test_idx += idx[n_train:]
    return np.array(train_idx), np.array(test_idx)

def choose_imposters(y: np.ndarray, imposter_subject_frac: float=0.2, seed=42):
    """
    Selects a subset of subjects to be imposters (completely unseen at train time).
    Returns mask arrays for enrolled vs imposter subjects.
    """
    set_seed(seed)
    classes = np.unique(y)
    n_imp = max(1, int(len(classes) * imposter_subject_frac)) if len(classes) > 1 else 0
    imp_classes = set(random.sample(list(classes), n_imp)) if n_imp>0 else set()
    enrolled_mask = np.array([cls not in imp_classes for cls in y])
    imposter_mask = np.array([cls in imp_classes for cls in y])
    return enrolled_mask, imposter_mask, sorted(list(imp_classes))

# ------------------------------
# Open-set logic (imposter detection)
# ------------------------------

def calibrate_threshold(model: SimpleANN, X_val: np.ndarray, y_val: np.ndarray, target_tpr: float=0.95):
    """
    Calibrate softmax max-probability threshold. We compute the distribution of max softmax
    for *correctly classified* validation samples and choose a threshold such that
    target_tpr of them are above the threshold.
    """
    P = model.predict_proba(X_val)
    yhat = np.argmax(P, axis=1)
    correct_mask = (yhat == y_val)
    maxp = np.max(P, axis=1)
    vals = np.sort(maxp[correct_mask])
    if len(vals) == 0:
        return 0.5  # fallback
    k = int(max(0, math.floor((1 - target_tpr) * len(vals))))
    thresh = vals[k] if k < len(vals) else vals[-1]
    return float(thresh)

def predict_with_unknown(model: SimpleANN, X: np.ndarray, threshold: float):
    P = model.predict_proba(X)
    maxp = np.max(P, axis=1)
    yhat = np.argmax(P, axis=1)
    # -1 indicates "imposter/unknown"
    yhat_open = np.where(maxp >= threshold, yhat, -1)
    return yhat_open, P, maxp

# ------------------------------
# Main experiment
# ------------------------------

def run_experiment(
    dataset_root: str,
    output_dir: str,
    img_size: Tuple[int,int]=(64,64),
    k_values: List[int]=None,
    train_ratio: float=0.6,
    imposter_subject_frac: float=0.2,
    ann_epochs: int=60,
    ann_lr: float=0.01,
    seed: int=42
):
    ensure_dir(output_dir)
    download_dataset_if_needed(dataset_root)
    print("[INFO] Loading dataset ...")
    ds = load_images_from_folder(dataset_root, img_size=img_size)
    print(f"[INFO] Loaded faces: {ds.X.shape[1]} images across {len(ds.subjects)} subjects; image size={img_size}")
    mn, p = ds.X.shape
    classes = np.unique(ds.y)
    n_classes = len(classes)

    if k_values is None:
        # reasonable defaults up to p-1
        max_k = min(200, p-1 if p>1 else 1)
        k_values = [min(x, max_k) for x in [10, 20, 30, 40, 50, 75, 100, max_k]]
        k_values = sorted(set([k for k in k_values if k>0]))

    # Imposter split: choose some subjects as imposters (unseen during training)
    enrolled_mask, imposter_mask, imp_classes = choose_imposters(ds.y, imposter_subject_frac=imposter_subject_frac, seed=seed)
    print(f"[INFO] Imposter subjects (held-out completely): {imp_classes}")
    # Filter dataset to only enrolled subjects for training/testing classification
    X_enrolled = ds.X[:, enrolled_mask]
    y_enrolled = ds.y[enrolled_mask]
    subjects_enrolled = sorted(list(set(y_enrolled.tolist())))

    # Train/test split on enrolled set
    train_idx, test_idx = per_subject_split(X_enrolled, y_enrolled, train_ratio=train_ratio, seed=seed)
    X_train = X_enrolled[:, train_idx]
    y_train = y_enrolled[train_idx]
    X_test_enrolled = X_enrolled[:, test_idx]
    y_test_enrolled = y_enrolled[test_idx]

    # Imposter test set (all images from imposter subjects)
    X_test_imp = ds.X[:, imposter_mask]
    y_test_imp = ds.y[imposter_mask]
    # For evaluation, imposters will be labeled -1

    # Results containers
    results = {
        "k_values": [],
        "train_acc": [],
        "test_acc_enrolled": [],
        "open_set_metrics": [],  # list of dicts per k
        "best_k": None,
        "subjects": ds.subjects,
        "img_size": img_size,
        "imposter_subjects": [int(x) for x in imp_classes],
    }

    best_acc = -1.0
    best_k = None

    for k in k_values:
        print(f"\n[INFO] === Running PCA with k={k} ===")
        pca = pca_eigenfaces(X_enrolled, k=k)
        Omega_train = project(X_train, pca.mean, pca.eigenfaces).T  # shape (N_train, k)
        Omega_test_enr = project(X_test_enrolled, pca.mean, pca.eigenfaces).T
        Omega_test_imp = project(X_test_imp, pca.mean, pca.eigenfaces).T if X_test_imp.size>0 else np.zeros((0,k), dtype=np.float32)

        # Scale features (zero mean unit variance) to help ANN
        def zscore(A):
            mu = A.mean(axis=0, keepdims=True)
            sd = A.std(axis=0, keepdims=True) + 1e-8
            return (A - mu) / sd, mu, sd

        Xtr, mu, sd = zscore(Omega_train)
        Xte_enr = (Omega_test_enr - mu) / sd
        Xte_imp = (Omega_test_imp - mu) / sd if Omega_test_imp.size>0 else np.zeros_like(Omega_test_imp)

        # Validation split from training
        tr_idx, val_idx = per_subject_split(np.arange(Xtr.shape[0]), y_train, train_ratio=0.85, seed=seed)
        Xtr2, ytr2 = Xtr[tr_idx], y_train[tr_idx]
        Xval, yval = Xtr[val_idx], y_train[val_idx]

        cfg = ANNConfig(
            input_dim=k,
            hidden_dims=(128, 64),
            num_classes=len(subjects_enrolled),
            lr=ann_lr,
            epochs=ann_epochs,
            batch_size=32,
            seed=seed
        )
        model = SimpleANN(cfg)
        model.fit(Xtr2, ytr2, X_val=Xval, y_val=yval, verbose=True)

        train_acc = model.accuracy(Xtr, y_train)
        test_acc = model.accuracy(Xte_enr, y_test_enrolled)

        # Calibrate open-set threshold on validation
        tau = calibrate_threshold(model, Xval, yval, target_tpr=0.95)

        # Open-set predictions
        yhat_open_enr, P_enr, maxp_enr = predict_with_unknown(model, Xte_enr, tau)
        yhat_open_imp, P_imp, maxp_imp = predict_with_unknown(model, Xte_imp, tau) if Xte_imp.size>0 else (np.array([], dtype=int), None, None)

        # Open-set metrics
        # For enrolled test: correct if predicted class == true class (and not unknown)
        enr_correct = (yhat_open_enr == y_test_enrolled)
        enr_unknown = (yhat_open_enr == -1)
        enr_acc_known = (enr_correct).mean() if yhat_open_enr.size>0 else float('nan')
        # For imposters: correct detection if predicted == -1
        imp_correct = (yhat_open_imp == -1) if yhat_open_imp.size>0 else np.array([])
        imp_det_rate = imp_correct.mean() if imp_correct.size>0 else float('nan')

        results["k_values"].append(k)
        results["train_acc"].append(float(train_acc))
        results["test_acc_enrolled"].append(float(test_acc))
        results["open_set_metrics"].append({
            "threshold": float(tau),
            "enrolled_accuracy_open": float(enr_acc_known),
            "imposter_detection_rate": float(imp_det_rate),
            "n_test_enrolled": int(Xte_enr.shape[0]),
            "n_test_imposters": int(Xte_imp.shape[0]),
        })

        if test_acc > best_acc:
            best_acc = test_acc
            best_k = k

        # Save eigenfaces montage for this k (first 16)
        save_eigenfaces_montage(pca.eigenfaces, ds.shape_hw, os.path.join(output_dir, f"eigenfaces_k{k}.png"), max_faces=16)

    results["best_k"] = int(best_k) if best_k is not None else None

    # Plot Accuracy vs k
    plt.figure()
    plt.plot(results["k_values"], results["test_acc_enrolled"], marker='o')
    plt.xlabel("k (number of eigenfaces)")
    plt.ylabel("Test Accuracy (enrolled only)")
    plt.title("Accuracy vs k (PCA + ANN)")
    plt.grid(True)
    acc_plot_path = os.path.join(output_dir, "accuracy_vs_k.png")
    plt.savefig(acc_plot_path, dpi=150, bbox_inches='tight')
    plt.close()

    # Save results JSON
    res_path = os.path.join(output_dir, "results.json")
    with open(res_path, "w") as f:
        json.dump(results, f, indent=2)
    print(f"[INFO] Results saved to {res_path}")
    print(f"[INFO] Accuracy plot saved to {acc_plot_path}")

    # Generate report PDF with results
    report_pdf = os.path.join(output_dir, "Face_Recognition_PCA_ANN_Report.pdf")
    generate_report_pdf(report_pdf, results, dataset_root, acc_plot_path, eigenfaces_glob=output_dir)
    print(f"[INFO] Report generated: {report_pdf}")
    return results

# ------------------------------
# Visualization helpers
# ------------------------------

def save_eigenfaces_montage(eigenfaces: np.ndarray, hw: Tuple[int,int], out_path: str, max_faces: int=16):
    h, w = hw
    k = eigenfaces.shape[1]
    n = min(k, max_faces)
    cols = int(np.ceil(np.sqrt(n)))
    rows = int(np.ceil(n / cols))
    fig_w = cols * 2.0
    fig_h = rows * 2.0
    plt.figure(figsize=(fig_w, fig_h))
    for i in range(n):
        ef = eigenfaces[:, i].reshape(h, w)
        ef_norm = (ef - ef.min()) / (ef.max() - ef.min() + 1e-12)
        plt.subplot(rows, cols, i+1)
        plt.imshow(ef_norm, cmap='gray')
        plt.axis('off')
        plt.title(f"PC{i+1}")
    plt.tight_layout()
    plt.savefig(out_path, dpi=150, bbox_inches='tight')
    plt.close()

# ------------------------------
# Report generation (ReportLab)
# ------------------------------

def generate_report_pdf(pdf_path: str, results: Dict, dataset_root: str, acc_plot_path: str, eigenfaces_glob: str):
    from reportlab.lib.pagesizes import A4
    from reportlab.pdfgen import canvas
    from reportlab.lib.units import cm

    c = canvas.Canvas(pdf_path, pagesize=A4)
    W, H = A4
    margin = 2*cm
    y = H - margin

    def header(title):
        nonlocal y
        c.setFont("Helvetica-Bold", 16)
        c.drawString(margin, y, title)
        y -= 0.8*cm

    def para(text, size=11, leading=14):
        nonlocal y
        c.setFont("Helvetica", size)
        for line in textwrap.wrap(text, width=95):
            c.drawString(margin, y, line)
            y -= leading
        y -= 0.2*cm

    import textwrap

    # Title
    header("Face Recognition using PCA (Eigenfaces) + ANN")
    para("This report summarizes a PCA + ANN pipeline for face recognition, including surrogate covariance PCA for eigenfaces, a simple backprop neural network for classification, and open-set imposter detection via softmax-thresholding.")

    header("Dataset & Preprocessing")
    para(f"Dataset root: {dataset_root}")
    para("Images are converted to grayscale, resized to 64x64, vectorized (mn x p), mean-centered, and projected onto the top-k principal components (eigenfaces).")

    header("Methodology")
    para("1) Build Face_Db (mn x p). 2) Compute mean face M (mn x 1). 3) Mean-center: Δ = X - M. "
         "4) Surrogate covariance S = ΔᵀΔ (p x p). 5) Eigen-decomposition of S; map eigenvectors back to image space to get eigenfaces. "
         "6) Project each face to k-D signature ω. 7) Train an ANN on ω to predict identity. 8) Calibrate a softmax threshold on validation data for imposter detection.")

    if results.get("k_values"):
        header("Results (Enrolled Only)")
        para(f"k values tried: {results['k_values']}")
        para(f"Test accuracy (per k): {np.round(np.array(results['test_acc_enrolled']),3).tolist()}")
        para(f"Best k: {results.get('best_k')}")

        # Insert accuracy plot
        if os.path.exists(acc_plot_path):
            try:
                c.drawImage(acc_plot_path, margin, y-9*cm, width=W-2*margin, height=8*cm, preserveAspectRatio=True, mask='auto')
                y -= 9.5*cm
            except Exception as e:
                para(f"(Plot could not be embedded: {e})")

        header("Open-Set (Imposter) Metrics")
        osm = results["open_set_metrics"]
        lines = [f"k={k}: thr={round(d['threshold'],3)}, enroll_acc_open={round(d['enrolled_accuracy_open'],3)}, imp_det_rate={round(d['imposter_detection_rate'],3)}"
                 for k,d in zip(results['k_values'], osm)]
        para(" | ".join(lines))

    header("Notes")
    para("If this PDF shows placeholders or empty plots, run the script locally to download the dataset and regenerate results. The script produces images and a fresh PDF with actual metrics.")

    c.showPage()
    c.save()

# ------------------------------
# CLI
# ------------------------------

def main():
    parser = argparse.ArgumentParser(description="PCA + ANN Face Recognition")
    parser.add_argument("--dataset_root", type=str, default="dataset", help="Path to dataset root directory")
    parser.add_argument("--output_dir", type=str, default="outputs", help="Directory to save results")
    parser.add_argument("--img_h", type=int, default=64)
    parser.add_argument("--img_w", type=int, default=64)
    parser.add_argument("--k_values", type=str, default="", help="Comma-separated k values (e.g., 10,20,30)")
    parser.add_argument("--train_ratio", type=float, default=0.6)
    parser.add_argument("--imposter_subject_frac", type=float, default=0.2, help="Fraction of subjects held-out as imposters")
    parser.add_argument("--epochs", type=int, default=60)
    parser.add_argument("--lr", type=float, default=0.01)
    parser.add_argument("--seed", type=int, default=42)
    args = parser.parse_args()

    k_values = None
    if args.k_values.strip():
        k_values = [int(x) for x in args.k_values.split(",") if x.strip().isdigit()]

    results = run_experiment(
        dataset_root=args.dataset_root,
        output_dir=args.output_dir,
        img_size=(args.img_h, args.img_w),
        k_values=k_values,
        train_ratio=args.train_ratio,
        imposter_subject_frac=args.imposter_subject_frac,
        ann_epochs=args.epochs,
        ann_lr=args.lr,
        seed=args.seed
    )

if __name__ == "__main__":
    main()
